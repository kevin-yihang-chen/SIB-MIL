#### general settings
name: Horseshoe
train_type: linreg
gpu_ids: [2]


#### datasets
data:
  name: "simulated"
  n: 10000
  scenario: 1

#### Checkpoint settings
checkpoints:
  path: "./checkpoints/HorseshoeMLP_L3_S1/"
  save_checkpoint_freq: 5


#### Optimizer settings
optimizer:
  opt_method: "ADAM"
  lr: 0.005  # Learning rate
  weight_decay: 0.001

#### training settings: learning rate scheme, loss, optimizer
train:
  model_name: "HorseshoeMLP"

  num_epochs: 100
  batch_size: 1024
  train_size: 1
  n_blocks: 3

  beta: 0.0001

  horseshoe_scale:
  global_cauchy_scale: 1.
  weight_cauchy_scale: 1.
  beta_rho_scale: -4.
  log_tau_mean:
  log_tau_rho_scale: -5.
  bias_rho_scale: -5.
  log_v_mean:
  log_v_rho_scale: -5.

  in_channels: 1
  out_channels: 1

  loss: "ELBO"
