#### general settings
name: R2D2
train_type: linreg
gpu_ids: [2]


#### datasets
data:
  name: "simulated"
  n: 10000
  scenario: 1

#### Checkpoint settings
checkpoints:
  path: "./checkpoints/R2D2MLP_L3_S1/"
  save_checkpoint_freq: 5


#### Optimizer settings
optimizer:
  opt_method: "ADAM"
  lr: 0.005  # Learning rate
  weight_decay: 0.001

#### training settings: learning rate scheme, loss, optimizer
train:
  model_name: "R2D2MLP"

  num_epochs: 100
  batch_size: 1024
  train_size: 1
  n_blocks: 3

  beta: 0.00001

  r2d2_scale:
  prior_phi_prob: 0.6
  prior_psi_shape: 0.5
  beta_rho_scale: [-4.5, 0.05]
  bias_rho_scale: [-4.5, 0.05]
  weight_xi_shape: 0.3
  weight_omega_shape: 0.5

  in_channels: 1
  out_channels: 1

  loss: "ELBO"
